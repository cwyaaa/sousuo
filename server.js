// åŠ è½½æœ¬åœ°ç¯å¢ƒå˜é‡ï¼ˆæœ¬åœ°å¼€å‘æ—¶æœ‰ç”¨ï¼ŒVerceléƒ¨ç½²æ—¶ä¸ä¼šå½±å“ï¼‰
require('dotenv').config();

const express = require('express');
const { OpenAI } = require('openai');

const app = express();
const port = process.env.PORT || 3000; // æ”¯æŒ Vercel åŠ¨æ€ç«¯å£ï¼Œä¹Ÿæ”¯æŒæœ¬åœ°é»˜è®¤3000

// åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // è‡ªåŠ¨è¯»å–ï¼Œæ— éœ€æ‰‹åŠ¨å¡«key
});

// ä¸­é—´ä»¶ï¼šå…è®¸è§£æ JSON è¯·æ±‚
app.use(express.json());

// ç®€å•æ ¹è·¯ç”±ï¼Œé˜²æ­¢è®¿é—® "/" æŠ¥é”™
app.get('/', (req, res) => {
  res.send('ğŸš€ Server is up and running!');
});

// AI æœç´¢æ¥å£
app.post('/api/chat', async (req, res) => {
  const userMessage = req.body.messages?.[0]?.content; // é˜²æ­¢å‡ºé”™ï¼ŒåŠ äº†ä¿æŠ¤

  if (!userMessage) {
    return res.status(400).json({ error: 'ç¼ºå°‘ç”¨æˆ·æ¶ˆæ¯å†…å®¹ã€‚' });
  }

  try {
    // è°ƒç”¨ OpenAI API
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: userMessage }],
      max_tokens: 1024,
      temperature: 0.6,
    });

    // è¿”å› AI çš„å›å¤
    res.json({
      choices: [
        {
          message: response.choices[0].message,
        },
      ],
    });
  } catch (error) {
    console.error('âŒ OpenAI API è¯·æ±‚å¤±è´¥ï¼š', error.message);
    res.status(500).json({ error: 'AI æœç´¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…ç½®æˆ–ç½‘ç»œè¿æ¥ã€‚' });
  }
});

// å¯åŠ¨æœåŠ¡å™¨ï¼ˆæœ¬åœ°å¼€å‘æ—¶ç”¨ï¼‰
if (process.env.NODE_ENV !== 'production') {
  app.listen(port, () => {
    console.log(`ğŸš€ Local server running at http://localhost:${port}`);
  });
}

// æ³¨æ„ï¼šVerceléƒ¨ç½²æ—¶ï¼Œä¸éœ€è¦ app.listenï¼ŒVercelè‡ªå·±å¤„ç†
module.exports = app; // Vercelè¯†åˆ«è¿™ä¸ªå‡ºå£
